# üéì AI-Powered Learning Platform
### Interactive Quiz Generator & RAG Chatbot with PDF Analysis

> **Built for:** BeyondChats Hiring Assignment  
> **Date:** October 2025  
> **Tech Stack:** React, TypeScript, Express, Gemini 2.0, Pinecone, MongoDB, Cloudinary

---

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Setup Instructions](#setup-instructions)
- [Deployment](#deployment)
- [API Documentation](#api-documentation)
- [Key Implementation Details](#key-implementation-details)

---

## üéØ Overview

A comprehensive full-stack application that transforms PDF documents into interactive learning experiences through:

1. **AI-Powered Quiz Generation** - Adaptive quiz creation with scoring and performance analytics
2. **RAG-Based Chatbot** - Intelligent Q&A system using vector search and LLM
3. **PDF Management** - Cloud storage with conversation history tracking
4. **Interactive UI** - Professional, ChatGPT-like interface

---

## ‚ú® Features

### üéÆ 1. Interactive Quiz Generator

#### Smart Question Generation
- **Adaptive Question Count**: Gemini 2.0 intelligently determines optimal question count based on content depth
- **Quality Over Quantity**: Avoids forced questions from sparse content
- **Content-Aware**: Rich content ‚Üí more questions, sparse content ‚Üí fewer questions
- **Multiple Question Types**: MCQ (60%), SAQ (30%), LAQ (10%)

#### Interactive Quiz Taking
- **Question-by-Question Navigation**: Clean, focused quiz-taking experience
- **Dedicated Quiz Page**: Professional full-page layout (`/take-quiz`)
- **Real-time Progress Tracking**: Visual progress bar and answered count
- **Smart Answer Validation**: Automatic scoring with normalization

#### Performance Analytics
- **Overall Score**: Circular progress meter with percentage
- **Performance Badges**: Excellent (‚â•80%), Good (‚â•60%), Average (‚â•40%), Needs Improvement (<40%)
- **Topic-Wise Analysis**: Shows strong/weak areas with visual meters
- **Detailed Review**: Question-by-question breakdown with explanations
- **Color-Coded Results**: Green for correct, red for incorrect answers

#### PDF Selection Options
- **Upload New PDF**: Traditional upload flow
- **Use Previously Uploaded**: Select from conversation history
- **Smart Download**: Automatically fetches from Cloudinary/local storage

### üí¨ 2. RAG-Based Chatbot

#### Intelligent Document Chat
- **Vector Search with Pinecone**: Semantic search across document chunks
- **Gemini 2.0 Integration**: Natural, conversational responses
- **Multi-Document Support**: Switch between different uploaded PDFs
- **Persistent Chat History**: MongoDB storage with conversation management

#### Smart Chunking Strategy
- **Page-Based Chunking**: 1 chunk per page (preserves context)
- **Intelligent Merging**: Combines pages <100 words for better context
- **Page Number Preservation**: Maintains source page references
- **Adaptive Context**: 3-5 top chunks sent to Gemini (vs original 2)

#### Enhanced Response Generation
- **Always Helpful**: Attempts to answer even when exact info not found
- **Makes Connections**: Links user query to available content
- **Suggests Alternatives**: Recommends related questions when applicable
- **Natural Tone**: No technical jargon or relevance scores in responses
- **Clean Source Citations**: Simple filename references

#### Advanced Features
- **Markdown Support**: Rich text formatting in responses (**bold**, *italic*, lists, etc.)
- **Conversation History**: Load previous chats with full context
- **Recent Conversations**: Sidebar showing all chat sessions
- **Message Count**: Track conversation activity
- **Real-time Auto-scroll**: Smooth message updates

### üìÑ 3. PDF Management System

#### Cloud Storage Integration
- **Cloudinary Upload**: Automatic PDF upload to cloud storage
- **MongoDB References**: Stores Cloudinary URLs for retrieval
- **Local Backup**: Keeps files locally as fallback
- **Smart URL Resolution**: Priority - Cloudinary ‚Üí Local ‚Üí API

#### PDF Viewer Features
- **Instant Preview**: Shows PDF immediately upon selection
- **Page Navigation**: Previous/Next with page counter
- **Zoom Controls**: 50% - 300% zoom levels
- **Rotation**: 90¬∞ rotation increments
- **Reset View**: Quick reset to default view
- **Side-by-Side Layout**: PDF visible while chatting (ChatGPT-style)

#### File Management
- **Namespace System**: Unique identifier per document
- **Cross-Feature Access**: PDFs available in both Quiz and Chat
- **Migration Support**: Tools to sync existing Pinecone data
- **Conversation Linking**: Each PDF linked to its chat history

### üé® 4. Professional UI/UX

#### Modern Design
- **Gradient Backgrounds**: Beautiful color schemes
- **Responsive Layout**: Works on mobile, tablet, and desktop
- **Fixed ChatGPT-Style Layout**: Scrollable messages, fixed sidebars
- **Loading States**: Smooth loading indicators throughout
- **Error Handling**: User-friendly error messages

#### Navigation
- **Home Page**: Feature showcase with CTAs
- **Quiz Generator** (`/quiz`): Generate and manage quizzes
- **Take Quiz** (`/take-quiz`): Dedicated quiz-taking page
- **RAG Chat** (`/chat`): Interactive document chat
- **React Router**: Smooth client-side navigation

---

## üèóÔ∏è Architecture

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Frontend (React)                      ‚îÇ
‚îÇ  Home ‚Üí Quiz Generator ‚Üí Take Quiz ‚Üí RAG Chat               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Backend (Express + TypeScript)            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Quiz     ‚îÇ    Chat    ‚îÇ   PDF        ‚îÇ  Conversation‚îÇ ‚îÇ
‚îÇ  ‚îÇ Controller ‚îÇ Controller ‚îÇ  Management  ‚îÇ  Management  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì              ‚Üì              ‚Üì              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Gemini 2.0 ‚îÇ ‚îÇ  Pinecone    ‚îÇ ‚îÇ  Cloudinary  ‚îÇ ‚îÇ   MongoDB    ‚îÇ
‚îÇ    Flash     ‚îÇ ‚îÇ  (Vectors)   ‚îÇ ‚îÇ   (PDFs)     ‚îÇ ‚îÇ  (History)   ‚îÇ
‚îÇ              ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îÇ - Quiz Gen   ‚îÇ ‚îÇ - Text       ‚îÇ ‚îÇ - PDF        ‚îÇ ‚îÇ - Messages   ‚îÇ
‚îÇ - Chat       ‚îÇ ‚îÇ   Chunks     ‚îÇ ‚îÇ   Storage    ‚îÇ ‚îÇ - Metadata   ‚îÇ
‚îÇ   Responses  ‚îÇ ‚îÇ - Semantic   ‚îÇ ‚îÇ - URLs       ‚îÇ ‚îÇ - Topics     ‚îÇ
‚îÇ              ‚îÇ ‚îÇ   Search     ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

#### Quiz Generation Flow
```
1. User uploads PDF or selects from library
   ‚Üì
2. Backend extracts text page-by-page (pdfjs-dist)
   ‚Üì
3. Groups pages into batches (default: 3 pages)
   ‚Üì
4. For each batch:
   - Send to Gemini 2.0 with previous summary
   - Gemini decides question count based on content
   - Generates MCQs, SAQs, LAQs adaptively
   - Returns summary for next batch continuity
   ‚Üì
5. Aggregates all questions and returns
   ‚Üì
6. User takes quiz on dedicated page
   ‚Üì
7. Auto-scoring with topic-wise performance analysis
```

#### RAG Chat Flow
```
1. User uploads PDF
   ‚Üì
2. Text extracted and chunked by pages
   - Smart merging: pages <100 words combined
   - Maintains page numbers and boundaries
   ‚Üì
3. Parallel processing:
   ‚îú‚îÄ‚Üí Text chunks ‚Üí Pinecone (vector embeddings)
   ‚îî‚îÄ‚Üí PDF file ‚Üí Cloudinary (cloud storage)
   ‚Üì
4. Conversation record created in MongoDB:
   - Namespace, filename
   - Cloudinary URL, local file ID
   - Messages array
   ‚Üì
5. User asks question:
   ‚Üì
6. Vector search in Pinecone (top 5 relevant chunks)
   ‚Üì
7. Top 3-5 chunks sent to Gemini 2.0
   ‚Üì
8. Gemini generates intelligent response:
   - Uses context intelligently
   - Makes connections when direct answer not found
   - Provides helpful suggestions
   ‚Üì
9. Response saved to MongoDB with sources
   ‚Üì
10. User sees formatted response with markdown
```

---

## üõ†Ô∏è Tech Stack

### Frontend
| Technology | Purpose | Version |
|------------|---------|---------|
| **React** | UI Framework | 18.3.1 |
| **TypeScript** | Type Safety | 5.6.2 |
| **Vite** | Build Tool | 6.0.1 |
| **Tailwind CSS** | Styling | 3.4.15 |
| **React Router** | Client-side Routing | 6.x |
| **React PDF** | PDF Viewing | 9.1.1 |
| **React Markdown** | Rich Text Rendering | Latest |
| **Lucide React** | Icons | 0.454.0 |

### Backend
| Technology | Purpose | Version |
|------------|---------|---------|
| **Express** | Web Framework | 4.21.1 |
| **TypeScript** | Type Safety | 5.6.3 |
| **Gemini 2.0 Flash** | LLM (Quiz + Chat) | Latest |
| **Pinecone** | Vector Database | 6.1.2 |
| **MongoDB (Mongoose)** | Document Database | 8.19.1 |
| **Cloudinary** | Cloud Storage | 2.7.0 |
| **pdfjs-dist** | PDF Parsing | 4.8.69 |
| **Multer** | File Upload | 1.4.5 |

### Cloud Services
- **MongoDB Atlas** - Database hosting
- **Pinecone** - Vector embeddings storage
- **Cloudinary** - PDF file storage
- **Google Gemini** - AI/LLM processing

---

## üöÄ Setup Instructions

### Prerequisites
- Node.js 18+ and npm
- MongoDB Atlas account (free tier)
- Pinecone account (free tier)
- Cloudinary account (free tier)
- Google Gemini API key (free tier)

### 1. Clone Repository
```bash
git clone <repository-url>
cd Assignment
```

### 2. Backend Setup

```bash
cd backend
npm install
```

Create `.env` file:
```env
PORT=3000
GEMINI_API_KEY=your_gemini_api_key
PINECONE_API_KEY=your_pinecone_api_key
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_cloudinary_api_key
CLOUDINARY_API_SECRET=your_cloudinary_api_secret
MONGODB_URI=your_mongodb_atlas_connection_string
```

Start backend:
```bash
npm run dev
```

**Backend runs on:** `http://localhost:3000`

### 3. Frontend Setup

```bash
cd frontend
npm install
```

Start frontend:
```bash
npm run dev
```

**Frontend runs on:** `http://localhost:5173` or `5174`

### 4. Access Application

- **Home**: http://localhost:5173/
- **Quiz Generator**: http://localhost:5173/quiz
- **RAG Chat**: http://localhost:5173/chat

---

## üåê Deployment

### Frontend Deployment (Vercel)

1. **Install Vercel CLI** (optional):
```bash
npm i -g vercel
```

2. **Deploy via Dashboard**:
   - Connect GitHub repository to Vercel
   - Set root directory: `frontend`
   - Framework preset: Vite
   - Build command: `npm run build`
   - Output directory: `dist`

3. **Environment Variables**:
   - Set `VITE_API_URL` to your backend URL

4. **Deploy**:
```bash
cd frontend
vercel --prod
```

### Backend Deployment (Railway/Render)

**Recommended: Railway.app or Render.com** (not Vercel due to serverless limitations)

#### Why Not Vercel for Backend?
- ‚ùå 10-60 second timeout (quiz generation takes 30-60s)
- ‚ùå 4.5MB request limit (PDFs can be 10MB)
- ‚ùå Ephemeral storage (file uploads need persistence)

#### Railway.app Setup:
1. Connect GitHub repository
2. Set root directory: `backend`
3. Add environment variables
4. Deploy automatically

#### Render.com Setup:
1. New Web Service
2. Connect repository
3. Root directory: `backend`
4. Build command: `npm install && npm run build`
5. Start command: `npm start`
6. Add environment variables

---

## üìö API Documentation

### Quiz Endpoints

#### Generate Quiz
```http
POST /api/quiz/generate
Content-Type: multipart/form-data

Body:
- pdf: File (PDF document)
- questionsPerPage: Number (optional, AI suggestion)
- batchSize: Number (default: 3)

Response:
{
  "success": true,
  "totalQuestions": 45,
  "totalPages": 30,
  "batchesProcessed": 10,
  "questions": [
    {
      "id": "q_1_1234567890",
      "type": "mcq",
      "question": "What is...?",
      "options": ["A", "B", "C", "D"],
      "correctAnswer": "B",
      "explanation": "...",
      "pageNumbers": [1, 2],
      "difficulty": "medium",
      "topic": "Introduction"
    }
  ],
  "breakdown": { "mcq": 27, "saq": 13, "laq": 5 }
}
```

### Chat Endpoints

#### Upload PDF for RAG
```http
POST /api/chat/upload
Content-Type: multipart/form-data

Body:
- pdf: File (PDF document)

Response:
{
  "success": true,
  "chunks": 25,
  "totalChunks": 25,
  "namespace": "document_1234567890",
  "filename": "document.pdf",
  "cloudinaryUrl": "https://cloudinary.com/...",
  "fileId": "1234567890-document.pdf"
}
```

#### Query Document
```http
POST /api/chat/query
Content-Type: application/json

Body:
{
  "query": "What is the main topic?",
  "namespace": "document_1234567890"
}

Response:
{
  "success": true,
  "answer": "Based on the document...",
  "sources": ["document.pdf"],
  "confidence": "high"
}
```

#### Get Conversations
```http
GET /api/chat/conversations

Response:
{
  "success": true,
  "conversations": [
    {
      "id": "...",
      "title": "Chat with document",
      "namespace": "document_1234567890",
      "filename": "document.pdf",
      "cloudinaryUrl": "https://...",
      "messageCount": 10,
      "updatedAt": "2025-10-08T..."
    }
  ]
}
```

#### Get Conversation History
```http
GET /api/chat/conversations/:namespace

Response:
{
  "success": true,
  "messages": [
    {
      "type": "user",
      "content": "What is...?",
      "timestamp": "2025-10-08T..."
    },
    {
      "type": "bot",
      "content": "Based on the document...",
      "timestamp": "2025-10-08T..."
    }
  ],
  "conversation": { ... }
}
```

### Utility Endpoints

```http
GET  /api/health                        # Health check
GET  /api/chat/namespaces              # List Pinecone namespaces
GET  /api/chat/pdf/:namespace          # Get PDF URL
POST /api/chat/migrate                 # Migrate Pinecone data to MongoDB
POST /api/chat/update-local-files      # Link local files to conversations
```

---

## üîë Key Implementation Details

### 1. Adaptive Quiz Generation Logic

**Problem**: Fixed questions per page led to:
- Too many low-quality questions from sparse pages
- Forced questions with little content
- Repetitive questions

**Solution**: Let Gemini 2.0 decide
```typescript
// Prompt instructs Gemini to:
1. Analyze content depth
2. Generate 0-3 questions per page adaptively
3. Prioritize quality over quantity
4. Skip if content too sparse
```

**Result**: High-quality, content-appropriate quizzes

### 2. Smart Page-Based Chunking

**Problem**: Fixed-size chunking (1000 chars) led to:
- Pages split mid-sentence
- Lost context at chunk boundaries
- Difficult to trace sources

**Solution**: Page-aware chunking
```typescript
function chunkTextByPages(pages, minWords = 100) {
  // Strategy:
  // 1. One chunk per page (default)
  // 2. If page < 100 words, check next page
  // 3. If both small, merge into single chunk
  // 4. Preserve [Page X] markers
  // 5. Track page numbers in metadata
}
```

**Benefits**:
- ‚úÖ Natural page boundaries preserved
- ‚úÖ Small pages intelligently merged
- ‚úÖ Easy source attribution
- ‚úÖ Better context for RAG

### 3. Enhanced RAG Response Generation

**Problem**: Original implementation was too rigid:
- Only used 2 chunks (limited context)
- Failed when exact answer not found
- Technical responses with confidence scores

**Solution**: Intelligent, helpful chatbot
```typescript
// Now uses 3-5 chunks (adaptive)
const topChunksCount = ragResults.length >= 5 ? 5 : Math.max(3, ragResults.length);

// Enhanced prompt instructions:
- Try to answer from context
- If not found, use related info and make connections
- Suggest alternative questions
- Always provide value, never just say "can't answer"
- NO technical jargon (relevance scores, confidence levels)
```

**Result**: Natural, ChatGPT-like conversations

### 4. Triple Storage Architecture

**Challenge**: Support both new and old PDFs

**Solution**: Multi-layer storage
```
Upload PDF
    ‚Üì
‚îú‚îÄ‚Üí Pinecone (text chunks for RAG)
‚îú‚îÄ‚Üí Cloudinary (full PDF for viewing)
‚îú‚îÄ‚Üí Local FS (backup)
‚îî‚îÄ‚Üí MongoDB (URLs + metadata)

Retrieval Priority:
1. Cloudinary URL (best)
2. Local file path (fallback)
3. API endpoint (last resort)
```

**Benefits**:
- ‚úÖ PDFs always accessible
- ‚úÖ Graceful degradation
- ‚úÖ Migration-friendly

### 5. Conversation Management System

**MongoDB Schema Design**:
```typescript
Conversation {
  title: String
  namespace: String (Pinecone namespace)
  filename: String
  cloudinaryUrl: String (PDF in cloud)
  localFileId: String (local backup)
  messages: [ObjectId] (ref: Message)
  createdAt: Date
  updatedAt: Date
  isActive: Boolean
}

Message {
  type: 'user' | 'bot'
  content: String
  timestamp: Date
  metadata: {
    confidence: String
    sources: [String]
    query: String
    namespace: String
  }
}
```

**Features**:
- Per-document conversation threads
- Message history persistence
- Soft deletes (isActive flag)
- Indexed for fast queries

### 6. Interactive Quiz System

**State Management**:
```typescript
// Tracks:
- currentQuestionIndex: Number
- userAnswers: Array<{questionId, answer, isCorrect}>
- currentAnswer: String
- isSubmitted: Boolean

// Navigation:
- Previous/Next with answer saving
- Auto-load saved answers when navigating back
- Progress tracking (X/Y answered)

// Submission:
- Includes current answer in final calculation
- Validates all answers against correct answers
- Calculates score and topic performance
- Generates performance analytics
```

**Analytics Calculation**:
```typescript
// Overall score
score = correctAnswers / totalQuestions * 100

// Topic performance
for each topic:
  topicScore = correctInTopic / totalInTopic * 100
  isStrong = topicScore >= 70%

// Performance level
‚â•80% = Excellent
‚â•60% = Good  
‚â•40% = Average
<40% = Needs Improvement
```

---

## üìÅ Project Structure

```
Assignment/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.tsx                 # Landing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ QuizGenerator.tsx        # Quiz generation interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TakeQuiz.tsx             # Dedicated quiz-taking page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InteractiveQuiz.tsx      # Interactive quiz component
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat.tsx                 # RAG chatbot interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PDFViewer.tsx            # PDF viewer component
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SourceSelector.tsx       # (Legacy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                      # Router configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tsx                     # Entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.css                    # Global styles + markdown CSS
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf.worker.min.mjs           # PDF.js worker
‚îÇ   ‚îú‚îÄ‚îÄ vercel.json                      # Vercel config
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quizController.ts        # Quiz generation logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chatController.ts        # Chat, upload, conversations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geminiService.ts         # Gemini 2.0 integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pineconeService.ts       # Vector operations + chunking
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cloudinaryService.ts     # PDF cloud storage
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mongodbService.ts        # Database connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Conversation.ts          # Conversation schema
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Message.ts               # Message schema
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quizRoutes.ts           # Quiz API routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chatRoutes.ts           # Chat API routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdfExtractor.ts          # Page-wise PDF extraction
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrateExistingPDFs.ts   # Migration utility
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ updateLocalFileIds.ts    # File linking utility
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.ts                    # Express server + MongoDB init
‚îÇ   ‚îú‚îÄ‚îÄ uploads/                         # Local PDF storage (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ kill-port.cjs                    # Auto port cleanup
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îî‚îÄ‚îÄ README.md                            # This file
```

---

## üéì Learning & Insights

### Design Decisions

1. **Why Page-Based Chunking?**
   - Easier source attribution
   - Natural content boundaries
   - Better user experience ("found on page 5")

2. **Why 3-5 Chunks to Gemini (not 2)?**
   - More context = better answers
   - Can make connections across pages
   - Still fits in Gemini context window

3. **Why Triple Storage (Pinecone + Cloudinary + MongoDB)?**
   - Pinecone: Fast semantic search (text only)
   - Cloudinary: Reliable PDF viewing
   - MongoDB: Conversation persistence
   - Each serves specific purpose

4. **Why Adaptive Question Count?**
   - Content varies greatly across pages
   - Fixed count leads to poor questions
   - AI better at judging content depth

5. **Why Dedicated Quiz Page?**
   - Professional exam-like experience
   - Distraction-free environment
   - Better focus and completion rates

### Challenges Solved

1. **Large PDF Processing** ‚Üí Batch processing with summaries
2. **Token Limits** ‚Üí Smart chunking and context management
3. **Context Loss** ‚Üí Page boundaries and summary continuity
4. **Poor Question Quality** ‚Üí Let AI decide count adaptively
5. **Missing PDFs for Old Uploads** ‚Üí Migration tools + local backup
6. **Technical UI** ‚Üí Removed confidence scores, added markdown
7. **Cramped Layout** ‚Üí ChatGPT-style fixed scroll layout

---

## üîí Security Considerations

- API keys in `.env` (not committed to git)
- File size limits (10MB)
- CORS enabled for frontend
- Input validation on all endpoints
- Soft deletes (data never truly deleted)
- Sanitized filenames for storage

---

## üìà Performance Optimizations

1. **Parallel Processing**: Pinecone upload, Cloudinary upload run concurrently
2. **Smart Caching**: Conversations cached, namespaces cached
3. **Efficient Queries**: MongoDB indexes on namespace and timestamps
4. **Lazy Loading**: PDFs load on demand, not upfront
5. **Batch Processing**: Pages processed in groups for efficiency

---

## üß™ Testing

### Manual Testing Checklist

**Quiz Generator:**
- [ ] Upload new PDF ‚Üí generates quiz
- [ ] Select uploaded PDF ‚Üí generates quiz
- [ ] Click "Start Interactive Quiz" ‚Üí navigates to `/take-quiz`
- [ ] Answer questions ‚Üí navigation works
- [ ] Submit quiz ‚Üí see results and analytics
- [ ] Check topic performance ‚Üí strong/weak indicators

**RAG Chat:**
- [ ] Upload PDF ‚Üí processes successfully
- [ ] Ask question ‚Üí gets relevant answer
- [ ] Check formatting ‚Üí markdown renders
- [ ] Click conversation ‚Üí loads history
- [ ] PDF viewer ‚Üí shows document
- [ ] Sources shown ‚Üí filename only (no percentages)

**PDF Management:**
- [ ] New upload ‚Üí appears in both Quiz & Chat
- [ ] Cloudinary storage ‚Üí URL saved in MongoDB
- [ ] Local backup ‚Üí file exists in uploads/
- [ ] Previous PDFs ‚Üí viewable if file available

---

## üí° Future Enhancements

- [ ] User authentication & authorization
- [ ] Quiz history and progress tracking
- [ ] Export quiz as PDF/DOCX
- [ ] Collaborative study sessions
- [ ] Video content integration (YouTube)
- [ ] Mobile app (React Native)
- [ ] Bulk PDF upload
- [ ] Custom quiz templates
- [ ] Spaced repetition algorithm
- [ ] Gamification (points, badges, leaderboards)

---

## üìä Key Metrics

### Performance
- **PDF Upload**: 2-5 seconds
- **Quiz Generation (30 pages)**: 40-60 seconds
- **RAG Query Response**: 2-4 seconds
- **Conversation Load**: <1 second

### Costs (Free Tiers)
- **Gemini 2.0 Flash**: Free tier (60 requests/minute)
- **Pinecone**: Free tier (1 index, 100K vectors)
- **MongoDB Atlas**: Free tier (512MB storage)
- **Cloudinary**: Free tier (25GB storage, 25GB bandwidth)

**Total: $0/month for moderate usage** üéâ

---

## üë®‚Äçüíª Development Notes

### Port Management
The backend includes automatic port cleanup:
```bash
npm run dev  # Automatically kills port 3000 before starting
```

### Migration Tools
```bash
# Sync Pinecone namespaces to MongoDB
POST /api/chat/migrate

# Link local files to conversations
POST /api/chat/update-local-files
```

### Debugging
- Backend logs all operations with emojis (üöÄ, ‚úÖ, ‚ùå)
- Frontend console shows PDF URLs, conversation loading
- MongoDB operations logged
- Gemini API calls tracked

---

## üèÜ Assignment Highlights

### Technical Excellence
1. ‚úÖ **Full-Stack TypeScript**: Type-safe throughout
2. ‚úÖ **Modern Stack**: Latest versions, best practices
3. ‚úÖ **Cloud-Native**: MongoDB Atlas, Pinecone, Cloudinary
4. ‚úÖ **AI Integration**: Gemini 2.0 Flash for quiz + chat
5. ‚úÖ **Production Ready**: Error handling, logging, validation

### Advanced Features
1. ‚úÖ **Adaptive AI**: Content-aware question generation
2. ‚úÖ **RAG Implementation**: Vector search + LLM
3. ‚úÖ **Smart Chunking**: Page-based with intelligent merging
4. ‚úÖ **Multi-Storage**: Distributed data architecture
5. ‚úÖ **Real-time Updates**: Live conversation management

### User Experience
1. ‚úÖ **Professional UI**: ChatGPT-like interface
2. ‚úÖ **Rich Formatting**: Markdown support in chat
3. ‚úÖ **Performance Analytics**: Detailed quiz insights
4. ‚úÖ **PDF Integration**: Side-by-side viewing
5. ‚úÖ **Responsive Design**: Works on all devices

### Code Quality
1. ‚úÖ **Clean Architecture**: Separation of concerns
2. ‚úÖ **Modular Design**: Reusable components and services
3. ‚úÖ **Error Handling**: Graceful degradation
4. ‚úÖ **Documentation**: Clear comments and structure
5. ‚úÖ **Scalability**: Ready for production scale

---

## üìû Support & Contact

For questions or issues regarding this assignment implementation:
- Review code comments for detailed explanations
- Check console logs for debugging information
- Refer to API documentation above
- See individual component README files in directories

---

## üìÑ License

MIT License - Created for BeyondChats Hiring Assignment

---

## üôè Acknowledgments

- **Google Gemini 2.0 Flash** - Advanced LLM capabilities
- **Pinecone** - Vector database infrastructure
- **MongoDB Atlas** - Database hosting
- **Cloudinary** - Media management
- **React & Vite** - Modern frontend tooling

---

**Built with ‚ù§Ô∏è and ‚òï for BeyondChats - October 2025**

*Demonstrating expertise in Full-Stack Development, AI Integration, Cloud Architecture, and Modern Web Technologies*
